{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This is a heavily documented notebook with exploratory data analyses for Telegram Channel Archive project\n",
    "https://github.com/githubbar/telegram_channel_archive\n",
    "\n",
    "\n",
    "For working with the SQLite backend we are choosing Ibis over Pandas for data analysis because it does execuste a lot of stuff at the backend and is therefore more suitable for large databases.\n",
    "see: https://voltrondata.com/blog/ibis-explained-making-dataframes-big-and-small-more-delightful\n",
    "\"\"\" \n",
    "\n",
    "# TEMP: conda activate /N/slate/oleykin/.conda/envs/tele\n",
    "# TEMP: conda list -e > requirements.txt\n",
    "\n",
    "\"\"\"Connect to SQLite DB\"\"\"\n",
    "import os\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "import numpy as np\n",
    "import ibis\n",
    "\n",
    "ibis.options.interactive = True\n",
    "ibis.options.repr.interactive.max_rows = 20\n",
    "\n",
    "con = ibis.sqlite.connect('db.sqlite')\n",
    "# con.list_tables()\n",
    "\n",
    "channel  = con.table('channel')\n",
    "msg = con.table('message')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>> Check start/end date for each channel \n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import duckdb\n",
    "from ibis import _\n",
    "t = msg.join(channel, msg.channel_id == channel.id) \n",
    "print('Date ranges for 2022')\n",
    "print(t.filter(_.date.cast(\"timestamp\").year() == 2022).group_by('title').aggregate(\n",
    "    min_time=_.date.min().cast(\"timestamp\"), \n",
    "    max_time=_.date.max().cast(\"timestamp\"),\n",
    ")\n",
    ")\n",
    "# group by channel name\n",
    "print('Date ranges for 2023')\n",
    "print(t.filter(_.date.cast(\"timestamp\").year() == 2023).group_by('title').aggregate(\n",
    "    min_time=_.date.min().cast(\"timestamp\"), \n",
    "    max_time=_.date.max().cast(\"timestamp\"),\n",
    ")\n",
    ")\n",
    "\n",
    "# TODO: timestamp diff not implemented in Ibis?\n",
    "# t = t.mutate(\n",
    "#     days_diff = _.max_time.delta(datetime.datetime.now(), 'day')    \n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>> Look at nulls (gap analysis); make sure they make sense.\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from ibis import _\n",
    "\n",
    "t = msg.join(channel, msg.channel_id == channel.id)\n",
    "t = t.filter(_.last_edit_date == None).select(_.title, _.text, _.total_views, _.last_edit_date)\n",
    "print(f'Found {t.title.count()} records with the field last_edit_date == NULL. These are mostly pinned posts')\n",
    "# t = t.filter(_.text != '')\n",
    "print(f'But some {t.title.count()} are not, because they have text in them')\n",
    "# Looks like an forward announcement for the next post, e.g. https://t.me/femagainstwar/237 and https://t.me/femagainstwar/238\n",
    "# or a group of images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>> Posting frequencies (own posts vs forwards; normalize by .. number of posts in channel/subs?)\n",
    "import datetime\n",
    "from rich import print\n",
    "from datetime import timedelta\n",
    "from ibis import _\n",
    "import pandas as pd\n",
    "\n",
    "# Identify three 100 day periods: one for each target channel\n",
    "PERIOD_DAYS = 100\n",
    "periods = {\n",
    "1166398892 : [[datetime.datetime(2022, 2, 25, 0, 0)], [datetime.datetime(2023, 2, 25, 0, 0)]],\n",
    "1724215937 : [[datetime.datetime(2022, 3, 15, 0, 0)], [datetime.datetime(2023, 3, 15, 0, 0)]],\n",
    "1744097497 : [[datetime.datetime(2022, 2, 27, 0, 0)], [datetime.datetime(2023, 2, 27, 0, 0)]]\n",
    "}\n",
    "for key in periods:\n",
    "    periods[key] = [(start[0], start[0] + datetime.timedelta(days=PERIOD_DAYS)) for start in periods[key]]\n",
    "\n",
    "\n",
    "t = msg.left_join(channel, msg.channel_id == channel.id)\n",
    "# t1 = t.filter((_.fwd_username != None)).select(_.title, _.text, _.total_views, _.last_edit_date)\n",
    "# print(f'Found {t1.title.count()} user forwards')\n",
    "# t2 = t.filter((_.fwd_channel_id != None)).select(_.title, _.text, _.total_views, _.last_edit_date)\n",
    "# print(f'Found {t2.title.count()} channel forwards')\n",
    "# Remove forwards\n",
    "tNoforwards = t.filter((_.fwd_channel_id == None) & (_.fwd_username == None) & (_.text != None))\n",
    "\n",
    "print('Post frequency per channel (forwards and pins removed)')\n",
    "dataByChannel = tNoforwards.group_by('title').aggregate(posts_per_day = _.count()/(PERIOD_DAYS*2)).to_pandas()\n",
    "print(dataByChannel)\n",
    "# t.to_csv('peroid_freq.csv')\n",
    "\n",
    "print('Post frequency per period (forwards and pins removed)')\n",
    "dataByPeriod = []\n",
    "for key in periods:\n",
    "    s1 = tNoforwards.count((_.channel_id == key) & (_.date.cast(\"timestamp\").between(periods[key][0][0], periods[key][0][1]))) \\\n",
    "        / (periods[key][0][1] - periods[key][0][0]).days\n",
    "    s2 = tNoforwards.count((_.channel_id == key) & (_.date.cast(\"timestamp\").between(periods[key][1][0], periods[key][1][1]))) \\\n",
    "        / (periods[key][1][1] - periods[key][1][0]).days\n",
    "    ttl = channel.filter(_.id == key).title.to_pandas()[0]\n",
    "    dataByPeriod.append({\"channel\": ttl, \"period1\" : s1.to_pandas(), \"period2\" : s2.to_pandas()})\n",
    "dataByPeriod = pd.DataFrame.from_records(dataByPeriod)\n",
    "print(dataByPeriod)\n",
    "# t.to_csv('peroid_freq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>  Altair charts \n",
    "# group by channel name\n",
    "# chart = (\n",
    "#     alt.Chart(t.group_by(\"title\").aggregate(count=_.count()))\n",
    "#     .mark_bar()\n",
    "#     .encode(\n",
    "#         x=\"title\",\n",
    "#         y=\"count\",\n",
    "#         tooltip=[\"title\", \"count\"],\n",
    "#     )\n",
    "#     .properties(width=1024, height=600)\n",
    "#     .interactive()\n",
    "# )\n",
    "# TODO tihs does it by time, do by date (bad interface)\n",
    "# date.histogram(200)\n",
    "# t = tDisplay.date.histogram(binwidth=3600.0).cast(\"timestamp\").name('bucket')\n",
    "# t = tNoforwards.filter(t.title == \"Медиа Партизаны | Нет войне\").select('date')\n",
    "# chart = (\n",
    "#     alt.Chart(tDisplay.date.histogram(nbins=10))\n",
    "#     .mark_line()\n",
    "#     .encode(\n",
    "#         x=alt.X('date:T'),\n",
    "#         y='count()'\n",
    "#     )\n",
    "#     .properties(width=1024, height=600)\n",
    "#     .interactive()\n",
    "# )\n",
    "\n",
    "# chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>> Export posts with media info\n",
    "\n",
    "import os\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "import numpy as np\n",
    "import ibis\n",
    "from ibis import _\n",
    "import ibis.selectors as s\n",
    "\n",
    "ibis.options.interactive = True\n",
    "ibis.options.repr.interactive.max_rows = 20\n",
    "\"\"\"\n",
    "con = ibis.sqlite.connect('db.sqlite')\n",
    "channel  = con.table('channel')\n",
    "msg = con.table('message')\n",
    "media = con.table('media')\n",
    "\"\"\"\n",
    "t = msg.join(channel, msg.channel_id == channel.id) # drop id_right column\n",
    "t = t.mutate(fwd_title=t['fwd_title'].cast('str'))\n",
    "t = t.mutate(fwd_username=t['fwd_username'].cast('str'))\n",
    "t = t.mutate(fwd_channel_id=t['fwd_channel_id'].cast('str'))\n",
    "# t = t.limit(100)\n",
    "\n",
    "# Add isPin pin posts \n",
    "t = t.mutate(isPin =(_.text == None))\n",
    "\n",
    "# Add isForward column\n",
    "t = t.mutate(isForward=(_.fwd_channel_id != None) | (_.fwd_username != None))\n",
    "\n",
    "# Add count columns for each media type\n",
    "type_list = media.distinct(on='type')['type'].to_pandas().to_list()\n",
    "for mediaType in type_list:\n",
    "    m = media.filter(_.type==mediaType).group_by([\"channel_id\", \"message_id\"]).agg(_.count().name(f'{mediaType}_count'))\n",
    "    # NOTE: left join below to have NULL if no media count and 1 or more otherwise\n",
    "    t = t.left_join(m, [t.channel_id == m.channel_id, t.id == m.message_id])\n",
    "    t = t.select(~s.matches('channel_id_right') & ~s.matches('message_id'))\n",
    "\n",
    "# Drop all unused columns\n",
    "cols = [\n",
    "    'id',\n",
    "    'date',\n",
    "    'text',\n",
    "    # 'mentions',\n",
    "    'total_views',\n",
    "    'total_fwds',\n",
    "    'hidden_edit',\n",
    "    'last_edit_date',\n",
    "    # 'scheduled',\n",
    "    # 'via_bot_id',\n",
    "    # 'noforwards',\n",
    "    # 'ttl_period',\n",
    "    'reactions',\n",
    "    'fwd_title',\n",
    "    'fwd_username',\n",
    "    'fwd_channel_id',\n",
    "    'title',\n",
    "    'isPin',\n",
    "    'isForward'\n",
    "]\n",
    "[cols.append(f'{mediaType}_count') for mediaType in type_list]\n",
    "\n",
    "t = t.select(cols)\n",
    "\n",
    "t.to_csv('reports/data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tele",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
